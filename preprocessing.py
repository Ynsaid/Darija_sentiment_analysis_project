import re
import emoji
import pickle
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences  
import Project.wordcloud_generator as wordcloud_generator 


arabic_stopwords = set([
"ู","ุก","ุกู","ุข","ุฃ","ุง","ุง?","ุงุงูุง","ุงุงูุชู","ุขุจ","ุฃุจู","ุงุจุชุฏุฃ","ุฃุจุฏุง","ุฃุจุฑูู","ุฃุจู","ุงุจูู",
"ุงุชุฎุฐ","ุงุซุฑ","ุงุซูุง","ุงุซูุงู","ุงุซูู","ุงุซููู","ุฃุฌู","ุงุฌู","ุฃุฌูุน","ุฃุญุฏ","ุงุญุฏ","ุฅุญุฏู","ุฃุฎู",
"ุฃุฎุจุฑ","ุฃุฎุฐ","ุขุฎุฑ","ุงุฎุฑู","ุงุฎูููู","ุฃุฎู","ุฅุฐ","ุฅุฐุง","ุฅุฐุงู","ุงุฐุง","ุขุฐุงุฑ","ุฅุฐูุง","ุฅุฐู",
"ุฃุฑุจุน","ุฃุฑุจุนุงุก","ุฃุฑุจุนุฉ","ุงุฑุจุนุฉ","ุฃุฑุจุนูุงุฆุฉ","ุฃุฑุจุนูุฆุฉ","ุงุฑุจุนูู","ุงุฑุจุนูู","ุงุฑุชุฏู","ุฃุฑู","ุฅุฒุงุก",
"ุงุณุชุญุงู","ุฃุณูู","ุฃุตุจุญ","ุงุตุจุญ","ุฃุตูุง","ุขุถ","ุฅุถุงูู","ุฃุถุญู","ุงุถุญู","ุงุทุงุฑ","ุฃุทุนู","ุงุนุงุฏุฉ",
"ุฃุนุทู","ุฃุนูู","ุงุนููุช","ุฃุบุณุทุณ","ุฃูููู","ุฃููู","ุงู","ุฃูุฑูู","ุฃูุนู ุจู","ุฃูุจู","ุฃูุชูุจุฑ","ุฃูุซุฑ",
"ุงูุซุฑ","ุงูุฏ","ุขู","ุฃู","ุฃูุง","ุฅูุง","ุฅููุง","ุงูุง","ุงูุงุฎูุฑุฉ","ุงูุฃูุงุก","ุงูุฃูู","ุงูุขู","ุงูุงู",
"ุงูุงูู","ุงูุงููู","ุงูุชู","ุงูุชู","ุงูุซุงูู","ุงูุซุงููุฉ","ุงูุญุงูู","ุงูุฐุงุชู","ุงูุฐู","ุงูุฐู","ุงูุฐูู",
"ุงูุณุงุจู","ุฃูู","ุงูู","ุฃููู","ุงููุงุชู","ุงููุชุงู","ุงููุชูุง","ุงููุชูู","ุงููุฐุงู","ุงููุฐูู","ุงูููุงุชู",
"ุงููุงุถู","ุงูููุจู","ุงูููุช","ุฅูู","ุฅูู","ุงูู","ุงูู","ุฅูููููู","ุฅูููู","ุฅูููู","ุฅููููุง","ุฅููููู",
"ุงููู","ุงูููุง","ุงูููู","ุฃู","ุฃูุง","ุฃููุง","ุฅูุง","ุฅููุง","ุงูุง","ุฃูุงู","ุงูุงู","ุฃูุงูู","ุฃูุงููู",
"ุฃูุฏ","ุฃูุณ","ุงูุณ","ุฃูุณู","ุงูุณู","ุขูููู","ุฃู","ุฃููู","ุฅู","ุฅููู","ุงู","ุฃูุง","ุขูุงุก","ุฃูุจุฃ",
"ุงูุจุฑู","ุฃูุช","ุฃูุชู","ุงูุช","ุฃูุชู","ุฃูุชูุง","ุฃูุชู","ุฃูุดุฃ","ุขููุง","ุฃููุณูู","ุฃููุณูุง","ุฃููุณูู",
"ุงูููุจ","ุฃูู","ุฅูู","ุงูู","ุฃููุง","ุฅููุง","ุงููุง","ุฃููู","ุขู","ุขูู","ุขูู","ุขูุงู","ุฃููุง","ุฃู",
"ุงู","ุฃูุช","ุฃูุดู","ุฃูู","ุงูู","ุฃููุงุก","ุฃููุงูู","ุฃููุฆู","ุฃูููู","ุฃู","ุฃูู","ุฃู","ุฅู","ุงู","ุงู",
"ุง?ู","ุฃูุง","ุฃูุงุฑ","ุงูุงุฑ","ุฅูุงู","ุฅูุงูู","ุฅูุงููุง","ุฅูุงูู","ุงูุงู","ูุฃููุงู","ุฃููุงู","ุฅูุงูุง",
"ุฅูุงู","ุฅูุงูุง","ุฅูุงูู","ุฅูุงููุง","ุฅูุงูู","ุฅูุงู","ุฃูุถุง","ุงูุถุง","ุฃูููู","ุฃูู","ุฅููู","ุจ","ุจุงุก",
"ุจุงุช","ุจุงุณู","ุจุฃู","ุจุฅู","ุจุงู","ุจุฎู","ุจุฏ","ุจุฏูุง","ุจุฑุณ","ุจูุณู","ุจุณู","ุจุณุจุจ","ุจุดูู","ุจุถุน",
"ุจุทุขู","ุจุนุฏ","ุจุนุฏุง","ุจุนุถ","ุจุนูุฏุง","ุจุบุชุฉ","ุจู","ุจููููู","ุจูู","ุจู","ุจู","ุจูุง","ุจูุฐุง","ุจุคุณุง",
"ุจุฆุณ","ุจูุฏ","ุจูู","ุจูููุง","ุฉ","ุช","ุชุงุก","ุชุงุฑุฉ","ุชุงุณุน","ุชุงูู","ุชุงููู","ุชุจุฏูู","ุชุฌุงู","ุชุญุช",
"ุชุญุช'","ุชุญููู","ุชุฎุฐ","ุชุฑู","ุชุณุน","ุชุณุนุฉ","ุชุณุนูุงุฆุฉ","ุชุณุนูุฆุฉ","ุชุณุนูู","ุชุณุนูู","ุชุดุฑูู","ุชุนุณุง",
"ุชุนูููู","ุชูุนูุงู","ุชูุนููู","ุชูุนููู","ุชููู","ุชููุงุก","ุชูู","ุชู","ุชููุฒ","ุชูู","ุชูู","ุชููููู",
"ุชููู","ุซ","ุซุงุก","ุซุงูุซ","ุซุงูู","ุซุงู","ุซุงูู","ุซุงููุฉ","ุซูุงุซ","ุซูุงุซุงุก","ุซูุงุซุฉ","ุซูุงุซูุงุฆุฉ",
"ุซูุงุซูุฆุฉ","ุซูุงุซูู","ุซูุงุซูู","ุซู","ุซููู","ุซูู","ุซูุงู","ุซูุงููุฆุฉ","ุซูุงููู","ุซูุงูู","ุซูุงููุฉ",
"ุซูุงููู","ุซููุฉ","ุซูููุฆุฉ","ุฌ","ุฌุงููู","ุฌุฏุง","ุฌุนู","ุฌูู","ุฌูุนุฉ","ุฌููุน","ุฌููู","ุฌูุงู","ุฌููููุฉ",
"ุฌูุฑ","ุฌูู","ุญ","ุญุงุก","ุญุงุฏู","ุญุงุฑ","ุญุงุดุง","ุญุงููุง","ุญุงู","ุญุจุฐุง","ุญุจูุจ","ุญุชู","ุญุฌุง","ุญุฏูุซ",
"ุญูุฐุงุฑู","ุญุฑู","ุญุฒูุฑุงู","ุญุณุจ","ุญูุง","ุญูู","ุญูุฏุง","ุญูู","ุญูุงูู","ุญูู","ุญููู","ุญูุซ","ุญูุซูุง",
"ุญูู","ุฎ","ุฎุงุก","ุฎุงุฑุฌ","ุฎุงุตุฉ","ุฎุงู","ุฎุงูุณ","ุฎุจููุฑ","ุฎูุง","ุฎูุงูุง","ุฎูุงู","ุฎูู","ุฎูุณ","ุฎูุณุฉ",
"ุฎูุณูุงุฆุฉ","ุฎูุณูุฆุฉ","ุฎูุณูู","ุฎูุณูู","ุฎููุณ","ุฏ","ุฏุงู","ุฏุฑูู","ุฏุฑู","ุฏูุงููู","ุฏููุงุฑ","ุฏูู",
"ุฏููู","ุฏูุณูุจุฑ","ุฏูู","ุฏููุงุฑ","ุฐ","ุฐุง","ุฐุงุช","ุฐุงู","ุฐุงู","ุฐุงูู","ุฐุงูู","ุฐูู","ุฐูู","ุฐูุจ",
"ุฐู","ุฐูู","ุฐูุช","ุฐููููู","ุฐููู","ุฑ","ุฑุงุก","ุฑุงุจุน","ุฑุงุญ","ุฑุฃู","ุฑูุจูู","ุฑุฌุน","ุฑุฒู","ุฑููุฏู",
"ุฑูุงู","ุฑูุซ","ุฒ","ุฒุงู","ุฒุนู","ุฒูุฏ","ุฒูุงุฑุฉ","ุณ","ุณุงุก","ุณุงุจุน","ุณุงุฏุณ","ุณุจุช","ุณุจุชูุจุฑ","ุณุจุญุงู",
"ุณุจุน","ุณุจุนุฉ","ุณุจุนูุงุฆุฉ","ุณุจุนูุฆุฉ","ุณุจุนูู","ุณุจุนูู","ุณุช","ุณุชุฉ","ุณุชููู","ุณุชูุงุฆุฉ","ุณุชูุฆุฉ",
"ุณุชูู","ุณุชูู","ุณุญูุง","ุณุฑุง","ุณุฑุนุงู","ุณูู","ุณูุนุง","ุณูุฉ","ุณูุชูู","ุณููุงุช","ุณูู","ุณูู","ุณูู",
"ุด","ุดุจุงุท","ุดุจู","ุดูุชููุงูู","ุดุชุงูู","ุดุฎุตุง","ุดุฑุน","ุดูุงู","ุดููู","ุดูู","ุต","ุตุงุฏ","ุตุงุฑ",
"ุตุจุงุญ","ุตุจุงุญุง","ุตุจุฑ","ุตุจุฑุง","ุตุฏูุง","ุตุฑุงุญุฉ","ุตูุฑ","ุตูู","ุตูู","ุถ","ุถุงุฏ","ุถุญูุฉ","ุถุฏ",
"ุถูู","ุท","ุทุงุก","ุทุงู","ุทุงููุง","ุทุฑุง","ุทูู","ุทูู","ุธ","ุธุงุก","ุธู","ุธูู","ุธููู","ุน","ุนุงุฏ",
"ุนุงุดุฑ","ุนุงู","ุนุงูุง","ุนุงูุฉ","ุนุฌุจุง","ุนุฏูู","ุนุฏุง","ุนุฏุฉ","ุนุฏุฏ","ุนูุฏูุณู","ุนุฏู","ุนุณู","ุนุดุฑ",
"ุนุดุฑุฉ","ุนุดุฑูู","ุนุดุฑูู","ุนู","ุนููู","ุนูู","ุนูู","ุนูู","ุนูู","ุนููู","ุนููู","ุนูููุง","ุนู",
"ุนูุฏ","ุนูุฏูุง","ุนูู","ุนููุง","ุนูุถ","ุนูุงูุง","ุนูู","ุบ","ุบุงุฏุฑ","ุบุงูุจุง","ุบุฏุง","ุบุฏุงุฉ","ุบูุฑ",
"ุบูู","ู","ูุงุก","ูุฃู","ูุฅู","ูุงู","ูุงูู","ูุจุฑุงูุฑ","ูุฑุงุฏู","ูุถูุง","ูุนู","ููุฏ","ููุท",
"ููุงู","ููุงู","ููุณ","ููุง","ููู","ููู","ููู","ูู","ููู","ูู","ูู","ูููุฑู","ููู","ูููุง",
"ู","ูุงุทุจุฉ","ูุงู","ูุงู","ูุงู","ูุจู","ูุฏ","ูุฑุด","ูุทู","ูููุง","ูููู","ููุฉ","ู","ูุงุฏ","ูุงู",
"ูุฃู","ูุฃูู","ูุงู","ูุงูุช","ูุงููู","ูุฃูู","ูุฃููู","ูุซูุฑุง","ููุฎ","ูุฐุง","ูุฐูู","ูุฑุจ","ูุณุง",
"ูู","ููุง","ููููุง","ููุชุง","ููู","ููููุง","ูู","ููุง","ูู","ูู","ููุช","ููู","ููููุง","ู","ูุง",
"ูุงุช","ูุงุฒุงู","ูุงุณููุง","ูุง ุณููุง","ูุงู","ูุฃู","ูุงูุฒุงู","ูุจูู","ูุฏู","ูุฏู","ูุฏู","ูุฏูู",
"ูุฐูู","ูุนู","ูุนููู","ูุนูุฑ","ููุงุก","ูู","ููู","ููููู","ูููู","ููุงูู","ูู","ููุง","ูููุง",
"ููุงุฐุง","ูู","ููุง","ูู","ููุง","ููุฐุง","ููู","ูู","ูููุงูุฉ","ูููุง","ูููุง","ูู","ููุช","ููุฑุฉ",
"ููุณ","ููุณุจ","ู","ูุง","ูุง ุฃูุนูู","ูุงุงููู","ูุง ุงููู","ูุงุจุฑุญ","ูุง ุจุฑุญ","ูุงุฏุงู","ูุงุฐุง","ูุงุฑุณ",
"ูุงุฒุงู","ูุงูุชุฆ","ูุงู","ูุงุฆุฉ","ูุงูุฒุงู","ูุงูู","ูุชู","ูุซู","ูุฐ","ูุฑุฉ","ูุฑูุฉ","ูุณุงุก","ูุน",
"ูุนุงุฐ","ูุนุธู","ูุนู","ูุนูุง","ููุงุจู","ููุงููู","ููุงููู","ููุงูููุง","ููุงูููู","ูููุงุฑ","ูููู",
"ููููู","ููุง","ูู","ููุฐ","ููู","ูููุง","ูู","ูููุง","ูุฆุฉ","ูุฆุชุงู","ููู","ู","ููู","ูุง",
"ูุจููุง","ูุญู","ูุญู","ููุฎู","ูุนู","ููุณ","ููุณู","ููุณู","ููุณูุง","ููุณู","ููุงูุฉ","ููููุจุฑ",
"ููู","ููุณุงู","ููู","ู","ูุง","ูุงุก","ููุงุชุงูู","ููุงุชูู","ููุงุชูู","ููุงุชููููู","ูุงูู","ูุจู",
"ููุฌู","ูุฐุง","ููุฐุง","ููุฐุงูู","ูุฐู","ููุฐูู","ููุฐูู","ููุฐููููู","ููุฐุง","ูู","ูููุง","ูููุฉ",
"ููู","ูู","ููุง","ููุฒุฉ","ูู","ููุง","ููุงู","ููุงูู","ูู","ูุคูุงุก","ููุคูุงุก","ูู","ูู","ููุง",
"ูููุง","ูููุงุช","ูููููุงุช","ุค","ู","ู6","ูุง","ูุฃุจู","ูุงุญุฏ","ูุงุถุงู","ูุงุถุงูุช","ูุงูุฏ","ูุงูุชู",
"ูุงูุฐู","ูุฃู","ูุฅู","ูุงู","ูุงูุงู","ูุงู","ูุงูุถุญ","ูุจูู","ูุซู","ูุฌุฏ","ูุฌูุฏ","ูุฑุงุกูู","ูุฑุฏ",
"ููุดูููุงูู","ูุนูู","ููู","ููุงู","ููุงูุช","ููุฏ","ููู","ููุงู","ููุงูุช","ููู","ููุง","ููุงูุฒุงู",
"ูููู","ููู","ููู","ููู","ูููุณ","ููุง","ููุน","ููู","ููุจ","ููุฐุง","ููู","ููู","ููู","ูููู",
"ู","ู","ุฆ","ูุงุก","ูุฌุฑู","ููุนูุงู","ููุนููู","ูููู","ููู","ูููู","ูููู","ูู","ููุงูุฑ","ููุจุบู",
"ููุงู","ููุฑู","ููููู","ููู","ููููู",

#of algeria 
"ูุงุด","ุฑุงู","ุบุงุฏู","ุจุงุด","ุฑูุญ","ุฒูุงูู","ุฏุฑุงูู","ูููุง","ุจุฒุงู","ูุจุงุณ",
"ุนูู","ูููุฉ","ูุฏุฑ","ุทุจูุฉ","ูุณูุฑูุช","ุจูุดูุฉ","ููุถ","ุญูุฑุฉ","ุฎุงูุชู","ูุญููู",
"ุณุญุช","ุดููู","ุฑุงูู","ุดุญุงู","ุนููุช","ูุถูุช","ููููุด","ูุฒู","ุชูุชุฉ","ููู ุฑุจู",
"ุฌุงุจ ุฑุจู","ุฏููุฉ","ูุงู","ูุงุน","ูุญุจุณ","ููุฑู","ููุฑู","ูุณูู","ูุญูุณ"
,"ูุนูุท","ููุฑุฌ","ููุตุฑ","ูุฌูุจ","ููุบุฑู","ุจูุงูุง ูููุงู",
"ุนูููู ุตุญุงุญ","ุฏุฑุช ูููุจู ุฏุงุฑ","ููุจุฑู","ูุงุฑุฏ","ูุงุจุง","ูุฒูุฒู","ุชูููุท","ุฏุฑููุด","ุชูุจุงู",
"ุทูุดุฉ","ุจุงุฒ","ูุณุฌูู","ูุดุจูู","ูุดูุฎ","ุถุฑู","ูููุชุด","ูููุชุง","ุจูุงู","ุนูุงุด","ุชุจุณู",
"ุงุฒุฑุจ","ุบุงูู","ุตุจุงุท","ุทูููุจูู","ูุฑูุณุฉ","ูุงูุงุช","ุชุฎุฏู","ูุทุงุทู","ูุงุด ุฏุฎูู",
"ุจุงูุงู","ุตุญุง","ูู ุฑุงู","ุจุณูุงูุฉ",
"ูุง ูุฒูุฉ","ุฃุฎุทููู","ููููู","ูุงูู","ุฒูุฌ ุฏูุงูู ุจุฑู","ูุง ุจูู","ุตุจุงุท","ุณุจูุทุงุฑ",
"ุตุฏู","ูุงุนูุฉ","ูุดุญุงู","ุดุฏู","ุดุญุงู ูุฐู","ููุง","ูุงุฏุงู","ูุงุณุฑ","ุฃุฑูู","ููู","ุฏูุฑ ุจุงูู"
])

train_path = r"C:\Users\Younes\Desktop\M2\Nlp\Project\datasets\train.csv"
val_path   = r"C:\Users\Younes\Desktop\M2\Nlp\Project\datasets\validation.csv"
test_path  = r"C:\Users\Younes\Desktop\M2\Nlp\Project\datasets\test.csv"

train_df = pd.read_csv(train_path)
val_df   = pd.read_csv(val_path)
test_df  = pd.read_csv(test_path)

df = pd.concat([train_df, val_df, test_df], ignore_index=True)

print(f"๐ Loaded total rows: {len(df)}")


def contains_arabic(text):
    return bool(re.search(r'[\u0600-\u06FF]', str(text)))

before = len(df)
df = df[df["text"].apply(contains_arabic)]
after = len(df)
print(f"๐งน Removed {before - after} non-Arabic rows. Remaining: {after}")


def clean_text_advanced(text):
    text = str(text)
    text = re.sub(r"http\S+|www\S+", "", text)        
    text = re.sub(r"@\w+", "", text)                   
    text = re.sub(r"#\w+", "", text)                   
    text = emoji.replace_emoji(text, replace='')       
    text = re.sub(r"[^\w\s]", " ", text)              
    text = re.sub(r"\d+", "", text)                    
    text = re.sub(r"\s+", " ", text).strip()           
    
    text = " ".join([word for word in text.split() if word not in arabic_stopwords])
    return text

df["text"] = df["text"].apply(clean_text_advanced)


df = df[["text", "label"]]
print("โ Text cleaned and replaced in same column.")


train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df["label"])
train_df, val_df  = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df["label"])

print(f"๐ Train size: {len(train_df)}")
print(f"๐ Validation size: {len(val_df)}")
print(f"๐ Test size: {len(test_df)}")


MAX_WORDS = 20000
MAX_LEN = 50

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token="<UNK>")
tokenizer.fit_on_texts(train_df["text"])

X_train = pad_sequences(tokenizer.texts_to_sequences(train_df["text"]), maxlen=MAX_LEN, padding="post")
X_val   = pad_sequences(tokenizer.texts_to_sequences(val_df["text"]),   maxlen=MAX_LEN, padding="post")
X_test  = pad_sequences(tokenizer.texts_to_sequences(test_df["text"]),  maxlen=MAX_LEN, padding="post")

y_train = train_df["label"].values
y_val   = val_df["label"].values
y_test  = test_df["label"].values

print("\nโ Tokenization done successfully!")
print("Train shape:", X_train.shape)
print("Validation shape:", X_val.shape)
print("Test shape:", X_test.shape)


train_df.to_csv("train_clean.csv", index=False)
val_df.to_csv("val_clean.csv", index=False)
test_df.to_csv("test_clean.csv", index=False)

with open("tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)

print("\n๐พ All cleaned datasets & tokenizer saved successfully!")